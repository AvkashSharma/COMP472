{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base-MLP-DS1\n",
    "a baseline Multi-Layered Perceptron with 1 hidden layer of100 neurons, sigmoid/logistic as activation function, stochastic gradient descent, and default values for the rest of the parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing and Splitting the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train1 = pd.read_csv(\"dataset/train_1.csv\", header=None)\n",
    "dataset_validate1 = pd.read_csv(\"dataset/val_1.csv\",header=None)\n",
    "dataset_test1_no_label_1 = pd.read_csv(\"dataset/test_no_label_1.csv\",header=None)\n",
    "dataset_test1_with_label_1 = pd.read_csv(\"dataset/test_with_label_1.csv\",header=None)\n",
    "X_training_1 = dataset_train1.iloc[:, :-1].values\n",
    "Y_training_1 = dataset_train1.iloc[:, -1].values\n",
    "X_validate_1 = dataset_validate1.iloc[:, :-1].values\n",
    "Y_validate_1 = dataset_validate1.iloc[:, -1].values\n",
    "X_test1 = dataset_test1_no_label_1.iloc[:, ].values\n",
    "Y_test1 = dataset_test1_with_label_1.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Using Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='logistic', hidden_layer_sizes=100, solver='sgd')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "classifier = MLPClassifier(hidden_layer_sizes=(100), activation='logistic', solver='sgd')\n",
    "classifier.fit(X_training_1,Y_training_1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate - Predict Using Validate Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_validate1_pred = classifier.predict(X_validate_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate - Output - Confusion Matrix and Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17 17 13 13 17 16 17  8 14  8 15  2 13 15  8 13 11  8 11 15  8  8  8 13\n",
      " 17  0 10  2 14  8 10 13 11  0  9 17 10 13  8 17 14  8  6 13  8  9  8 13\n",
      "  8 14 10 17 12  7 16 16  2  6 11  2 11  6 17 13 17 14 10  9 11 11 10  8\n",
      "  9 15  7  6  8  2  8 14 12  6 17 15  7 14 17  9 14  0  8 10 10 15  8  2\n",
      "  2  0 13 10 14  6  0 13 13 10 17  9 13 13 10  6 11 14 13 21 10 17  6 10\n",
      " 17  8 11 17 15 11 14  7  8 14 11 16 17  8 16  8 22 17 17 12  0  8 13 17\n",
      "  9  6  6 14 15  6 22  0 12 10 10  9  8  8 14 10 13 15  0 13 17  6  2  2\n",
      " 13  8 15 22  6 17 16 15 11  8 10  2 14 13 10 17  8  2 11 22  6  0  2  8\n",
      " 11 15  9 11  2 10  2 14  8 17 13  0  7  2  8  2  2 13 17 11 10 14 11  6\n",
      "  8  9  6  8  0 17  2  7 12  2 17 15 12  2 15 11 17 10 13 17  2  8 15]\n",
      "[[ 6  0  0  0  0  0  0  0  0  0  0  0  0  2  0  0  0  2  0  0  0  0  0  0\n",
      "   0  0]\n",
      " [ 1  0  1  0  0  0  0  0  0  0  0  0  0  0  2  0  0  5  0  0  0  0  0  0\n",
      "   0  0]\n",
      " [ 0  0  9  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0\n",
      "   0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  1  0  1  0  0  2  3  0  1  0  0  0  0  0  0\n",
      "   0  0]\n",
      " [ 0  0  4  0  0  0  0  0  2  0  1  0  0  0  0  1  0  0  0  0  0  0  0  0\n",
      "   0  0]\n",
      " [ 0  0  1  0  0  0  0  0  1  0  3  0  0  0  0  2  0  1  0  0  0  0  0  0\n",
      "   0  0]\n",
      " [ 0  0  1  0  0  0  7  0  0  0  0  0  0  0  2  0  0  0  0  0  0  0  0  0\n",
      "   0  0]\n",
      " [ 0  0  0  0  0  0  0  5  1  0  0  2  0  1  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0]\n",
      " [ 0  0  0  0  0  0  0  0 10  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0]\n",
      " [ 0  0  0  0  0  0  0  0  3  6  0  0  0  0  0  0  1  0  0  0  0  0  0  0\n",
      "   0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  9  0  0  1  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0]\n",
      " [ 0  0  1  0  0  0  0  0  0  0  0  9  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0]\n",
      " [ 1  0  0  0  0  0  0  0  0  0  0  0  4  4  0  0  0  1  0  0  0  0  0  0\n",
      "   0  0]\n",
      " [ 1  0  0  0  0  0  0  1  0  0  1  0  0  6  0  0  0  1  0  0  0  0  0  0\n",
      "   0  0]\n",
      " [ 0  0  2  0  0  0  1  0  0  1  0  0  0  0  6  0  0  0  0  0  0  0  0  0\n",
      "   0  0]\n",
      " [ 0  0  0  0  0  0  0  0  3  0  2  0  0  0  0  4  0  1  0  0  0  0  0  0\n",
      "   0  0]\n",
      " [ 0  0  1  0  0  0  2  0  0  0  0  0  0  1  1  0  5  0  0  0  0  0  0  0\n",
      "   0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  2  0  0  0  0  2  0  6  0  0  0  0  0  0\n",
      "   0  0]\n",
      " [ 0  0  1  0  0  0  5  0  1  1  0  1  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0]\n",
      " [ 0  0  0  0  0  0  0  0  5  0  0  0  0  0  0  1  0  2  0  0  0  0  0  0\n",
      "   0  0]\n",
      " [ 0  0  0  0  0  0  1  0  0  0  0  2  0  2  3  0  0  0  0  0  0  0  0  0\n",
      "   0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  2  0  5  0  0  0  0  0  0  0  1  0  0\n",
      "   0  0]\n",
      " [ 1  0  0  0  0  0  0  0  0  0  1  1  0  2  0  0  0  0  0  0  0  0  4  0\n",
      "   0  0]\n",
      " [ 1  0  0  0  0  0  0  0  0  0  1  0  1  0  0  0  0  5  0  0  0  0  0  0\n",
      "   0  0]\n",
      " [ 0  0  0  0  0  0  0  0  2  1  0  0  1  0  0  0  0  4  0  0  0  0  0  0\n",
      "   0  0]\n",
      " [ 0  0  0  0  0  0  0  0  6  0  1  0  0  0  0  2  0  0  0  0  0  0  0  0\n",
      "   0  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.60      0.57        10\n",
      "           1       0.00      0.00      0.00         9\n",
      "           2       0.43      0.90      0.58        10\n",
      "           3       0.00      0.00      0.00         8\n",
      "           4       0.00      0.00      0.00         8\n",
      "           5       0.00      0.00      0.00         8\n",
      "           6       0.44      0.70      0.54        10\n",
      "           7       0.83      0.56      0.67         9\n",
      "           8       0.29      1.00      0.45        10\n",
      "           9       0.60      0.60      0.60        10\n",
      "          10       0.43      0.90      0.58        10\n",
      "          11       0.50      0.90      0.64        10\n",
      "          12       0.67      0.40      0.50        10\n",
      "          13       0.25      0.60      0.35        10\n",
      "          14       0.35      0.60      0.44        10\n",
      "          15       0.27      0.40      0.32        10\n",
      "          16       0.83      0.50      0.62        10\n",
      "          17       0.21      0.60      0.31        10\n",
      "          18       0.00      0.00      0.00         9\n",
      "          19       0.00      0.00      0.00         8\n",
      "          20       0.00      0.00      0.00         8\n",
      "          21       1.00      0.12      0.22         8\n",
      "          22       1.00      0.44      0.62         9\n",
      "          23       0.00      0.00      0.00         8\n",
      "          24       0.00      0.00      0.00         8\n",
      "          25       0.00      0.00      0.00         9\n",
      "\n",
      "    accuracy                           0.41       239\n",
      "   macro avg       0.33      0.38      0.31       239\n",
      "weighted avg       0.35      0.41      0.33       239\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import csv\n",
    "\n",
    "print(Y_validate1_pred)\n",
    "cm = confusion_matrix(Y_validate_1, Y_validate1_pred)\n",
    "print(cm)\n",
    "cr = classification_report(Y_validate_1, Y_validate1_pred)\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test - Predict Using Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test1_pred = classifier.predict(X_test1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test - Output - Confusion Matrix and Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 8 13 17  2  0 17 11 17 22 11  6  9 11  8  8 10  0  8  2  0 16  0  8 17\n",
      "  8 17 22  8 17  6 15 13 10 16 10 10  6  8 15  2 16 10 13 17 10 17 10 14\n",
      " 17  0  7 15 11 13 14 14  0  9 17 14 12  2 11 10 17  6  6 14 12 13 13 14\n",
      " 13  8 11  6 10 17  6  8]\n",
      "[[3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0]\n",
      " [0 0 3 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 2 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 2 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 1 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 1 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 1 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 2 0 0 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.75      0.60         4\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.75      0.75      0.75         4\n",
      "           3       0.00      0.00      0.00         3\n",
      "           4       0.00      0.00      0.00         2\n",
      "           5       0.00      0.00      0.00         2\n",
      "           6       0.43      0.75      0.55         4\n",
      "           7       1.00      0.33      0.50         3\n",
      "           8       0.30      1.00      0.46         3\n",
      "           9       1.00      0.50      0.67         4\n",
      "          10       0.22      0.67      0.33         3\n",
      "          11       0.50      0.75      0.60         4\n",
      "          12       0.50      0.33      0.40         3\n",
      "          13       0.43      0.75      0.55         4\n",
      "          14       0.50      1.00      0.67         3\n",
      "          15       0.33      0.33      0.33         3\n",
      "          16       1.00      1.00      1.00         3\n",
      "          17       0.25      0.75      0.38         4\n",
      "          18       0.00      0.00      0.00         3\n",
      "          19       0.00      0.00      0.00         2\n",
      "          20       0.00      0.00      0.00         3\n",
      "          21       0.00      0.00      0.00         3\n",
      "          22       0.50      0.33      0.40         3\n",
      "          23       0.00      0.00      0.00         2\n",
      "          24       0.00      0.00      0.00         3\n",
      "          25       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.44        80\n",
      "   macro avg       0.32      0.38      0.31        80\n",
      "weighted avg       0.36      0.44      0.36        80\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(Y_test1_pred)\n",
    "cm = confusion_matrix(Y_test1, Y_test1_pred)\n",
    "print(cm)\n",
    "cr = classification_report(Y_test1, Y_test1_pred)\n",
    "print(cr)\n",
    "\n",
    "pd.DataFrame(Y_test1_pred).to_csv('output/Base-MLP-DS1.csv', header = None)\n",
    "with open('output/Base-MLP-DS1.csv', 'a') as fd:\n",
    "    fd.write('\\n\\nConfusion Matrix\\n\\n')\n",
    "    fd.write(pd.DataFrame(cm).to_csv())\n",
    "    fd.write('\\n\\n Classification Report\\n\\n')\n",
    "    fd.write(cr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base-MLP-DS2\n",
    "a baseline Multi-Layered Perceptron with 1 hidden layer of100 neurons, sigmoid/logistic as activation function, stochastic gradient descent, and default values for the rest of the parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing and Splitting the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train2 = pd.read_csv(\"dataset/train_2.csv\", header=None)\n",
    "dataset_validate2 = pd.read_csv(\"dataset/val_2.csv\",header=None)\n",
    "dataset_test2_no_label_2 = pd.read_csv(\"dataset/test_no_label_2.csv\",header=None)\n",
    "dataset_test2_with_label_2 = pd.read_csv(\"dataset/test_with_label_2.csv\",header=None)\n",
    "X_training_2 = dataset_train2.iloc[:, :-1].values\n",
    "Y_training_2 = dataset_train2.iloc[:, -1].values\n",
    "X_validate_2 = dataset_validate2.iloc[:, :-1].values\n",
    "Y_validate_2 = dataset_validate2.iloc[:, -1].values\n",
    "X_test2 = dataset_test2_no_label_2.iloc[:, ].values\n",
    "Y_test2 = dataset_test2_with_label_2.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Using Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='logistic', hidden_layer_sizes=100, solver='sgd')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = MLPClassifier(hidden_layer_sizes=(100), activation='logistic', solver='sgd')\n",
    "classifier.fit(X_training_2,Y_training_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate - Predict Using Validate Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_validate2_pred = classifier.predict(X_validate_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate - Output - Confusion Matrix and Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9 7 1 ... 8 0 1]\n",
      "[[144   4   0   0   7   0   0   0   7   3]\n",
      " [  4 367   0   1   0   2   0   0   0   1]\n",
      " [  1   2  13   0   2   2   0   0  20   5]\n",
      " [  1   9   0  30   2   3   0   0   0   0]\n",
      " [ 13   0   1   0 100   6   0   0   4  26]\n",
      " [  0   7   0   1   4 145   0   0   1   7]\n",
      " [  0   7   0   0   3   0  31   0   1   3]\n",
      " [  1   2   0   0   0   2   0  39   0   1]\n",
      " [  4   9   0   0   5   0   1   0 127   4]\n",
      " [  2   3   1   0  15  12   0   0   1 341]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.87      0.86       165\n",
      "           1       0.90      0.98      0.94       375\n",
      "           2       0.87      0.29      0.43        45\n",
      "           3       0.94      0.67      0.78        45\n",
      "           4       0.72      0.67      0.69       150\n",
      "           5       0.84      0.88      0.86       165\n",
      "           6       0.97      0.69      0.81        45\n",
      "           7       1.00      0.87      0.93        45\n",
      "           8       0.79      0.85      0.82       150\n",
      "           9       0.87      0.91      0.89       375\n",
      "\n",
      "    accuracy                           0.86      1560\n",
      "   macro avg       0.87      0.77      0.80      1560\n",
      "weighted avg       0.86      0.86      0.85      1560\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(Y_validate2_pred)\n",
    "cm2 = confusion_matrix(Y_validate_2, Y_validate2_pred)\n",
    "print(cm2)\n",
    "cr2 = classification_report(Y_validate_2, Y_validate2_pred)\n",
    "print(cr2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test - Predict Using Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test2_pred = classifier.predict(X_test2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test - Output - Confusion Matrix and Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9 0 4 5 9 1 1 3 8 9 5 1 3 9 9 1 9 9 7 1 6 1 9 7 9 8 1 1 8 8 9 8 8 9 8 1 9\n",
      " 9 1 1 1 7 9 5 9 9 1 1 5 1 9 9 5 9 0 0 8 5 9 1 1 9 0 0 9 0 1 4 0 0 3 1 1 9\n",
      " 5 8 9 1 0 9 7 1 0 5 0 9 9 9 7 1 8 4 1 1 5 1 9 9 0 0 4 8 8 2 4 5 8 5 5 4 1\n",
      " 9 5 5 8 9 8 0 8 9 1 5 5 9 1 1 2 4 4 9 1 1 8 1 9 1 4 9 0 8 5 0 1 4 4 4 9 9\n",
      " 5 1 1 5 9 1 5 0 1 5 5 3 0 8 0 1 1 1 1 1 9 0 5 9 5 0 4 1 1 0 0 5 4 1 9 9 4\n",
      " 1 9 9 0 3 1 9 1 9 5 7 9 7 9 9 5 0 9 0 5 5 8 1 5 1 4 5 1 0 9 0 8 1 1 9 8 1\n",
      " 9 4 9 3 8 5 8 1 9 1 4 9 1 6 5 9 8 1 2 0 9 9 1 1 5 0 9 7 9 1 1 1 9 0 9 4 1\n",
      " 1 9 1 1 1 5 5 9 2 7 8 5 4 9 1 7 8 5 8 9 5 0 4 4 6 0 9 0 1 9 1 3 9 8 8 1 9\n",
      " 1 0 8 5 1 5 9 5 1 1 1 7 1 3 9 9 1 9 1 8 5 9 9 7 9 1 9 9 2 5 9 0 1 9 5 1 9\n",
      " 4 1 6 7 1 9 4 8 8 5 8 0 5 5 4 9 9 5 3 1 8 1 9 4 1 1 1 0 9 0 9 9 8 8 1 1 1\n",
      " 9 5 1 5 1 4 1 9 8 8 1 9 1 1 1 9 4 4 9 8 9 9 0 1 5 1 2 8 2 1 1 9 0 9 8 7 8\n",
      " 9 8 9 5 6 1 9 1 1 9 1 4 5 9 9 0 9 8 0 9 5 4 8 9 0 1 9 9 1 1 9 9 5 1 0 0 1\n",
      " 0 9 8 8 0 9 9 4 1 9 8 0 1 0 1 9 1 8 8 9 9 4 1 8 7 8 9 8 2 9 5 9 5 0 8 4 1\n",
      " 1 1 0 9 4 9 8 9 0 1 5 4 1 8 1 3 0 0 1 9 0 5 4 9 0 8 1 5 8 9 1 1 9 4 0 1 9\n",
      " 6 5]\n",
      "[[ 46   3   1   0   0   2   0   0   1   2]\n",
      " [  2 121   0   1   0   1   0   0   0   0]\n",
      " [  0   0   6   0   0   1   0   0   7   1]\n",
      " [  2   2   0   9   1   1   0   0   0   0]\n",
      " [  4   1   0   0  28   2   0   0   3  12]\n",
      " [  0   0   0   0   1  50   0   0   0   4]\n",
      " [  1   3   1   0   1   0   6   0   2   1]\n",
      " [  0   0   0   0   0   0   0  15   0   0]\n",
      " [  1   1   0   0   0   0   0   0  46   2]\n",
      " [  2   0   0   0   7   5   0   0   1 110]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.84      0.81        55\n",
      "           1       0.92      0.97      0.95       125\n",
      "           2       0.75      0.40      0.52        15\n",
      "           3       0.90      0.60      0.72        15\n",
      "           4       0.74      0.56      0.64        50\n",
      "           5       0.81      0.91      0.85        55\n",
      "           6       1.00      0.40      0.57        15\n",
      "           7       1.00      1.00      1.00        15\n",
      "           8       0.77      0.92      0.84        50\n",
      "           9       0.83      0.88      0.86       125\n",
      "\n",
      "    accuracy                           0.84       520\n",
      "   macro avg       0.85      0.75      0.78       520\n",
      "weighted avg       0.84      0.84      0.83       520\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(Y_test2_pred)\n",
    "cm2 = confusion_matrix(Y_test2, Y_test2_pred)\n",
    "print(cm2)\n",
    "cr2 = classification_report(Y_test2, Y_test2_pred)\n",
    "print(cr2)\n",
    "\n",
    "pd.DataFrame(Y_test2_pred).to_csv('output/Base-MLP-DS2.csv', header = None)\n",
    "with open('output/Base-MLP-DS2.csv', 'a') as fd:\n",
    "    fd.write('\\n\\nConfusion Matrix\\n\\n')\n",
    "    fd.write(pd.DataFrame(cm2).to_csv())\n",
    "    fd.write('\\n\\n Classification Report\\n\\n')\n",
    "    fd.write(cr2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
