{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base-MLP-DS1\n",
    "a baseline Multi-Layered Perceptron with 1 hidden layer of100 neurons, sigmoid/logistic as activation function, stochastic gradient descent, and default values for the rest of the parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing and Splitting the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train1 = pd.read_csv(\"dataset/train_1.csv\", header=None)\n",
    "dataset_validate1 = pd.read_csv(\"dataset/val_1.csv\",header=None)\n",
    "dataset_test1_no_label_1 = pd.read_csv(\"dataset/test_no_label_1.csv\",header=None)\n",
    "dataset_test1_with_label_1 = pd.read_csv(\"dataset/test_with_label_1.csv\",header=None)\n",
    "X_training_1 = dataset_train1.iloc[:, :-1].values\n",
    "Y_training_1 = dataset_train1.iloc[:, -1].values\n",
    "X_validate_1 = dataset_validate1.iloc[:, :-1].values\n",
    "Y_validate_1 = dataset_validate1.iloc[:, -1].values\n",
    "X_test1 = dataset_test1_no_label_1.iloc[:, ].values\n",
    "Y_test1 = dataset_test1_with_label_1.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Using Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='logistic', hidden_layer_sizes=100, solver='sgd')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "classifier = MLPClassifier(hidden_layer_sizes=(100), activation='logistic', solver='sgd')\n",
    "classifier.fit(X_training_1,Y_training_1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate - Predict Using Validate Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_validate1_pred = classifier.predict(X_validate_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate - Output - Confusion Matrix and Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 9 17 12 13 17 16 17  8 14  0 15  2 12  9  8 10  6  8 11  8  8  8  8 12\n",
      " 17 10 10  2 12  2 10 13 13  0 13 17 10 12  8 17 14  8  2 13  8  9 25 22\n",
      "  8  2 10 10 12  7 16  9  2  6 11  2 10 16 15 13 17 14 10  9 13 10 10  8\n",
      "  3 10  7  2  8  2  8 14 12  6 17 25  7  6  0  9 14 10  8 10 10 15 25  8\n",
      "  2  0 13 17 14  6  0 13  0 10 12  9 13 13 17  6  2 14 13 13 10 17  2 10\n",
      "  0  8 11 17 17 10 14  7 15 14 13 16 17  8 16  8 13 17 17 17  0  8 14 17\n",
      " 14  6  6  2 15  6 22  0 10 10 10  9  2  8 13 10 13 17  0 13 17 13 11  2\n",
      " 13  9 15 22  6 17 16  8  2  8 10  2 14  0 10 17  8 12 11 10  6  0  2  8\n",
      "  0 15  9 13  2 10  2  9  8 17 13  0 13  6  8  2  2 13 17 12 10 16 11  6\n",
      "  8  9 16  8  0  8  2 17  8  2  9 15 12  2  9 11  8 10 13 17  2  8  2]\n",
      "[[ 9  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0]\n",
      " [ 1  0  2  0  0  0  0  0  0  2  0  0  0  0  0  0  0  4  0  0  0  0  0  0\n",
      "   0  0]\n",
      " [ 0  0 10  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0]\n",
      " [ 0  0  0  1  0  0  0  0  0  1  0  1  0  0  2  3  0  0  0  0  0  0  0  0\n",
      "   0  0]\n",
      " [ 0  0  4  0  0  0  1  0  0  0  2  1  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0]\n",
      " [ 0  0  1  0  0  0  0  0  1  0  2  0  1  0  0  1  0  2  0  0  0  0  0  0\n",
      "   0  0]\n",
      " [ 0  0  1  0  0  0  7  0  0  0  0  0  0  0  1  0  1  0  0  0  0  0  0  0\n",
      "   0  0]\n",
      " [ 1  0  0  0  0  0  0  4  1  0  0  0  1  2  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0]\n",
      " [ 0  0  0  0  0  0  0  0 10  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0]\n",
      " [ 1  0  0  0  0  0  0  0  2  7  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0 10  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0]\n",
      " [ 0  0  2  0  0  0  0  0  0  0  3  5  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  1  2  0  4  3  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0]\n",
      " [ 1  0  0  0  0  0  0  0  0  0  1  0  2  5  0  0  0  1  0  0  0  0  0  0\n",
      "   0  0]\n",
      " [ 0  0  2  0  0  0  1  0  0  0  0  0  0  0  7  0  0  0  0  0  0  0  0  0\n",
      "   0  0]\n",
      " [ 0  0  0  0  0  0  0  0  5  0  2  0  0  0  0  2  0  1  0  0  0  0  0  0\n",
      "   0  0]\n",
      " [ 0  0  0  0  0  0  0  0  1  0  0  0  0  1  1  0  7  0  0  0  0  0  0  0\n",
      "   0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  1  2  0  0  0  0  0  0  7  0  0  0  0  0  0\n",
      "   0  0]\n",
      " [ 0  0  4  0  0  0  3  0  0  2  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0]\n",
      " [ 0  0  0  0  0  0  0  0  5  0  0  0  0  0  0  1  0  2  0  0  0  0  0  0\n",
      "   0  0]\n",
      " [ 0  0  1  0  0  0  1  0  0  0  0  0  1  4  1  0  0  0  0  0  0  0  0  0\n",
      "   0  0]\n",
      " [ 1  0  0  0  0  0  0  0  0  0  0  0  2  5  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  3  0  0  3  0  0  0  0  0  0  0  0  3  0\n",
      "   0  0]\n",
      " [ 1  0  0  0  0  0  0  0  0  0  2  0  0  0  0  0  0  5  0  0  0  0  0  0\n",
      "   0  0]\n",
      " [ 0  0  0  0  0  0  0  0  5  0  0  0  0  1  0  0  0  2  0  0  0  0  0  0\n",
      "   0  0]\n",
      " [ 0  0  0  0  0  0  0  0  3  0  0  0  0  0  0  1  0  2  0  0  0  0  0  0\n",
      "   0  3]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.90      0.72        10\n",
      "           1       0.00      0.00      0.00         9\n",
      "           2       0.37      1.00      0.54        10\n",
      "           3       1.00      0.12      0.22         8\n",
      "           4       0.00      0.00      0.00         8\n",
      "           5       0.00      0.00      0.00         8\n",
      "           6       0.54      0.70      0.61        10\n",
      "           7       1.00      0.44      0.62         9\n",
      "           8       0.30      1.00      0.47        10\n",
      "           9       0.50      0.70      0.58        10\n",
      "          10       0.34      1.00      0.51        10\n",
      "          11       0.71      0.50      0.59        10\n",
      "          12       0.36      0.40      0.38        10\n",
      "          13       0.20      0.50      0.29        10\n",
      "          14       0.58      0.70      0.64        10\n",
      "          15       0.25      0.20      0.22        10\n",
      "          16       0.88      0.70      0.78        10\n",
      "          17       0.27      0.70      0.39        10\n",
      "          18       0.00      0.00      0.00         9\n",
      "          19       0.00      0.00      0.00         8\n",
      "          20       0.00      0.00      0.00         8\n",
      "          21       0.00      0.00      0.00         8\n",
      "          22       1.00      0.33      0.50         9\n",
      "          23       0.00      0.00      0.00         8\n",
      "          24       0.00      0.00      0.00         8\n",
      "          25       1.00      0.33      0.50         9\n",
      "\n",
      "    accuracy                           0.42       239\n",
      "   macro avg       0.38      0.39      0.33       239\n",
      "weighted avg       0.39      0.42      0.35       239\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import csv\n",
    "\n",
    "print(Y_validate1_pred)\n",
    "cm = confusion_matrix(Y_validate_1, Y_validate1_pred)\n",
    "print(cm)\n",
    "cr = classification_report(Y_validate_1, Y_validate1_pred)\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test - Predict Using Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test1_pred = classifier.predict(X_test1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test - Output - Confusion Matrix and Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 6 13 17  2 18 17 11 17 22 13  6  9 11  8 11 10  0  8  2  0  6  0 15 17\n",
      "  8 17 13  8 17  6 15 17 10 16 10 10  6  8  8 12 16 10 13 13 17 17 10  2\n",
      " 17  0  7 15 22 13 14 14 17  9 17 14 13  2 11 11 17  6  6 14 12 13 13 13\n",
      " 13  8 13  6 10 17  6  8]\n",
      "[[3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0]\n",
      " [0 0 3 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 2 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 2 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 1 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 1 0 0 0 0 0 0 0 0]\n",
      " [0 0 1 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 2 1 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 2 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 2 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.75      0.75         4\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.75      0.75      0.75         4\n",
      "           3       0.00      0.00      0.00         3\n",
      "           4       0.00      0.00      0.00         2\n",
      "           5       0.00      0.00      0.00         2\n",
      "           6       0.33      0.75      0.46         4\n",
      "           7       1.00      0.33      0.50         3\n",
      "           8       0.38      1.00      0.55         3\n",
      "           9       1.00      0.50      0.67         4\n",
      "          10       0.29      0.67      0.40         3\n",
      "          11       0.60      0.75      0.67         4\n",
      "          12       0.50      0.33      0.40         3\n",
      "          13       0.25      0.75      0.38         4\n",
      "          14       0.50      0.67      0.57         3\n",
      "          15       0.00      0.00      0.00         3\n",
      "          16       1.00      0.67      0.80         3\n",
      "          17       0.21      0.75      0.33         4\n",
      "          18       1.00      0.33      0.50         3\n",
      "          19       0.00      0.00      0.00         2\n",
      "          20       0.00      0.00      0.00         3\n",
      "          21       0.00      0.00      0.00         3\n",
      "          22       1.00      0.67      0.80         3\n",
      "          23       0.00      0.00      0.00         2\n",
      "          24       0.00      0.00      0.00         3\n",
      "          25       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.42        80\n",
      "   macro avg       0.37      0.37      0.33        80\n",
      "weighted avg       0.41      0.42      0.37        80\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(Y_test1_pred)\n",
    "cm = confusion_matrix(Y_test1, Y_test1_pred)\n",
    "print(cm)\n",
    "cr = classification_report(Y_test1, Y_test1_pred)\n",
    "print(cr)\n",
    "\n",
    "pd.DataFrame(Y_test1_pred).to_csv('output/Base-MLP-DS1.csv', header = None)\n",
    "with open('output/Base-MLP-DS1.csv', 'a') as fd:\n",
    "    fd.write('\\n\\nConfusion Matrix\\n\\n')\n",
    "    fd.write(pd.DataFrame(cm).to_csv())\n",
    "    fd.write('\\n\\n Classification Report\\n\\n')\n",
    "    fd.write(cr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base-MLP-DS2\n",
    "a baseline Multi-Layered Perceptron with 1 hidden layer of100 neurons, sigmoid/logistic as activation function, stochastic gradient descent, and default values for the rest of the parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing and Splitting the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train2 = pd.read_csv(\"dataset/train_2.csv\", header=None)\n",
    "dataset_validate2 = pd.read_csv(\"dataset/val_2.csv\",header=None)\n",
    "dataset_test2_no_label_2 = pd.read_csv(\"dataset/test_no_label_2.csv\",header=None)\n",
    "dataset_test2_with_label_2 = pd.read_csv(\"dataset/test_with_label_2.csv\",header=None)\n",
    "X_training_2 = dataset_train2.iloc[:, :-1].values\n",
    "Y_training_2 = dataset_train2.iloc[:, -1].values\n",
    "X_validate_2 = dataset_validate2.iloc[:, :-1].values\n",
    "Y_validate_2 = dataset_validate2.iloc[:, -1].values\n",
    "X_test2 = dataset_test2_no_label_2.iloc[:, ].values\n",
    "Y_test2 = dataset_test2_with_label_2.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Using Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='logistic', hidden_layer_sizes=100, solver='sgd')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = MLPClassifier(hidden_layer_sizes=(100), activation='logistic', solver='sgd')\n",
    "classifier.fit(X_training_2,Y_training_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate - Predict Using Validate Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_validate2_pred = classifier.predict(X_validate_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate - Output - Confusion Matrix and Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9 7 1 ... 8 0 1]\n",
      "[[144   4   1   0   6   0   0   0   7   3]\n",
      " [  4 367   0   0   0   2   0   0   1   1]\n",
      " [  1   2  15   0   1   1   0   0  18   7]\n",
      " [  1   8   0  31   2   3   0   0   0   0]\n",
      " [ 13   0   0   0 102   6   0   0   4  25]\n",
      " [  0   7   0   1   5 145   0   0   0   7]\n",
      " [  1   6   0   0   3   1  30   0   1   3]\n",
      " [  1   3   0   0   0   2   0  38   0   1]\n",
      " [  4   9   0   0   4   0   2   0 127   4]\n",
      " [  2   3   1   0  13  12   1   0   3 340]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.87      0.86       165\n",
      "           1       0.90      0.98      0.94       375\n",
      "           2       0.88      0.33      0.48        45\n",
      "           3       0.97      0.69      0.81        45\n",
      "           4       0.75      0.68      0.71       150\n",
      "           5       0.84      0.88      0.86       165\n",
      "           6       0.91      0.67      0.77        45\n",
      "           7       1.00      0.84      0.92        45\n",
      "           8       0.79      0.85      0.82       150\n",
      "           9       0.87      0.91      0.89       375\n",
      "\n",
      "    accuracy                           0.86      1560\n",
      "   macro avg       0.88      0.77      0.80      1560\n",
      "weighted avg       0.86      0.86      0.85      1560\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(Y_validate2_pred)\n",
    "cm = confusion_matrix(Y_validate_2, Y_validate2_pred)\n",
    "print(cm)\n",
    "cr = classification_report(Y_validate_2, Y_validate2_pred)\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test - Predict Using Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test2_pred = classifier.predict(X_test2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test - Output - Confusion Matrix and Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9 0 4 5 9 1 1 3 8 9 5 1 3 9 9 1 9 9 7 1 6 1 9 7 9 8 1 1 8 8 9 8 8 9 8 1 5\n",
      " 9 1 1 1 7 9 5 9 9 1 1 5 1 9 9 5 9 0 0 8 5 9 1 1 9 0 0 9 0 1 4 0 0 3 0 1 9\n",
      " 5 8 9 1 0 9 7 1 0 5 0 9 9 9 7 1 8 4 1 1 5 1 9 9 0 0 4 8 8 2 4 5 8 5 5 4 1\n",
      " 9 5 5 8 9 8 0 8 9 1 5 5 9 1 1 2 4 4 9 1 1 8 1 9 1 4 9 0 8 5 0 1 4 4 4 9 9\n",
      " 5 1 1 5 9 1 5 0 1 5 5 3 0 8 0 1 1 1 1 1 9 0 5 9 5 0 4 1 1 0 0 5 4 1 9 9 4\n",
      " 1 9 4 0 3 1 9 1 9 5 7 9 7 9 9 5 0 9 0 5 5 8 1 5 1 4 5 8 0 9 0 8 1 1 9 8 1\n",
      " 9 4 9 3 9 5 8 1 9 1 4 9 1 6 5 9 8 1 2 0 9 9 1 1 5 0 9 7 9 1 1 1 9 0 9 5 1\n",
      " 1 9 1 1 1 5 5 9 2 7 8 5 4 9 1 7 8 5 8 9 5 0 4 4 6 3 9 0 1 9 1 3 9 8 8 1 9\n",
      " 1 0 8 5 1 5 9 5 1 1 1 7 1 3 9 9 1 9 1 8 5 9 9 7 9 1 9 9 2 5 9 0 1 9 5 1 9\n",
      " 4 1 0 7 1 9 4 8 8 5 8 0 5 5 4 9 9 5 3 1 8 1 9 4 1 1 1 0 9 0 9 9 8 8 1 1 1\n",
      " 9 5 1 5 1 4 1 9 8 8 1 9 1 1 1 9 4 4 9 8 9 9 0 1 5 1 2 8 2 1 1 9 0 9 8 7 8\n",
      " 9 8 0 5 6 1 9 1 1 9 1 4 5 9 9 0 9 8 0 9 5 4 8 9 0 1 9 9 1 1 9 9 5 1 0 0 1\n",
      " 0 9 8 8 0 9 9 4 1 9 8 0 1 0 1 9 1 8 8 9 9 4 1 8 7 8 9 8 2 9 5 9 5 0 8 4 1\n",
      " 1 1 0 9 4 9 8 9 0 1 5 4 1 8 1 3 0 0 1 9 0 5 4 9 0 8 1 5 8 9 1 1 9 4 0 1 9\n",
      " 6 5]\n",
      "[[ 46   2   1   0   0   2   0   0   2   2]\n",
      " [  3 120   0   1   0   1   0   0   0   0]\n",
      " [  0   0   6   0   0   1   0   0   7   1]\n",
      " [  1   2   0  10   0   2   0   0   0   0]\n",
      " [  5   1   0   0  29   2   0   0   3  10]\n",
      " [  0   0   0   0   1  50   0   0   0   4]\n",
      " [  2   3   1   0   1   0   5   0   2   1]\n",
      " [  0   0   0   0   0   0   0  15   0   0]\n",
      " [  1   1   0   0   0   0   0   0  45   3]\n",
      " [  2   0   0   0   7   6   0   0   1 109]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.84      0.80        55\n",
      "           1       0.93      0.96      0.94       125\n",
      "           2       0.75      0.40      0.52        15\n",
      "           3       0.91      0.67      0.77        15\n",
      "           4       0.76      0.58      0.66        50\n",
      "           5       0.78      0.91      0.84        55\n",
      "           6       1.00      0.33      0.50        15\n",
      "           7       1.00      1.00      1.00        15\n",
      "           8       0.75      0.90      0.82        50\n",
      "           9       0.84      0.87      0.85       125\n",
      "\n",
      "    accuracy                           0.84       520\n",
      "   macro avg       0.85      0.75      0.77       520\n",
      "weighted avg       0.84      0.84      0.83       520\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(Y_test2_pred)\n",
    "cm2 = confusion_matrix(Y_test2, Y_test2_pred)\n",
    "print(cm2)\n",
    "cr2 = classification_report(Y_test2, Y_test2_pred)\n",
    "print(cr2)\n",
    "\n",
    "pd.DataFrame(Y_test2_pred).to_csv('output/Base-MLP-DS2.csv', header = None)\n",
    "with open('output/Base-MLP-DS2.csv', 'a') as fd:\n",
    "    fd.write('\\n\\nConfusion Matrix\\n\\n')\n",
    "    fd.write(pd.DataFrame(cm2).to_csv())\n",
    "    fd.write('\\n\\n Classification Report\\n\\n')\n",
    "    fd.write(cr2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
