{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base-MLP-DS1\n",
    "a baseline Multi-Layered Perceptron with 1 hidden layer of100 neurons, sigmoid/logistic as activation function, stochastic gradient descent, and default values for the rest of the parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing and Splitting the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train1 = pd.read_csv(\"dataset/train_1.csv\", header=None)\n",
    "dataset_validate1 = pd.read_csv(\"dataset/val_1.csv\",header=None)\n",
    "dataset_test1_no_label_1 = pd.read_csv(\"dataset/test_no_label_1.csv\",header=None)\n",
    "dataset_test1_with_label_1 = pd.read_csv(\"dataset/test_with_label_1.csv\",header=None)\n",
    "X_training_1 = dataset_train1.iloc[:, :-1].values\n",
    "Y_training_1 = dataset_train1.iloc[:, -1].values\n",
    "X_validate_1 = dataset_validate1.iloc[:, :-1].values\n",
    "Y_validate_1 = dataset_validate1.iloc[:, -1].values\n",
    "X_test1 = dataset_test1_no_label_1.iloc[:, ].values\n",
    "Y_test1 = dataset_test1_with_label_1.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Using Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='logistic', hidden_layer_sizes=100, solver='sgd')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "classifier = MLPClassifier(hidden_layer_sizes=(100), activation='logistic', solver='sgd')\n",
    "classifier.fit(X_training_1,Y_training_1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate - Predict Using Validate Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_validate1_pred = classifier.predict(X_validate_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate - Output - Confusion Matrix and Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0 17 12 13 15 14 17  9 14  0  9  2 12 17 25 10  9  8 11 15  8  8  8 13\n",
      " 13 10 10  2 14  2 15 13 11  0 13  0 10 12  8 17  2  8  6 13  8  9 25 10\n",
      "  8  2 10 10 12  7  2  9  2  6 11  2 10  6 17 13 17 14 10  9 13 11 10  8\n",
      " 14  2  7  2  8  2  2 14 12  6 17 25  7  6 17  9 13 12  8 10 17  2 25  2\n",
      "  2  0 13  0  6 11  0 13 13  0 17  9 13 13 10  2  2 14 10 21 10 17  6 10\n",
      " 17  8 11 17  8 10 14  7  2 14 12 14 17  8 14  8 22 17 17 17  0  8 12 17\n",
      "  9  6  6 13 15  6 22 11 12 10 10  9  2  8 14 10 13 25 17 13 17 13  2 12\n",
      " 13  6 15 22  6 17 14 15 11  8 10  2 14  0  2 15  8 14 11 22  6  0  2  8\n",
      " 13 15  9 10  2 10 11 15  8 17 13  0  7  2  8  2  2 13 17 12 10 14 11  6\n",
      "  8  9 14  8 17  8  2 17 13  2 12 17 12  2  8 11 17 10 13 17  2  8  2]\n",
      "[[ 5  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  4  0  0  0  0  0  0\n",
      "   0  0]\n",
      " [ 1  0  1  0  0  0  0  0  0  0  0  1  0  1  0  3  0  2  0  0  0  0  0  0\n",
      "   0  0]\n",
      " [ 0  0 10  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0]\n",
      " [ 0  0  1  0  0  0  0  0  1  1  0  1  0  0  2  1  0  1  0  0  0  0  0  0\n",
      "   0  0]\n",
      " [ 0  0  7  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0]\n",
      " [ 0  0  2  0  0  0  0  0  1  0  3  0  0  0  1  0  0  1  0  0  0  0  0  0\n",
      "   0  0]\n",
      " [ 0  0  1  0  0  0  9  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0]\n",
      " [ 0  0  0  0  0  0  0  5  1  0  0  0  2  1  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0]\n",
      " [ 0  0  0  0  0  0  0  0 10  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0]\n",
      " [ 1  0  0  0  0  0  0  0  2  7  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0 10  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0]\n",
      " [ 0  0  1  0  0  0  0  0  0  0  2  6  1  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  7  3  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0]\n",
      " [ 2  0  0  0  0  0  0  0  0  0  0  0  1  5  0  0  0  2  0  0  0  0  0  0\n",
      "   0  0]\n",
      " [ 0  0  2  0  0  0  0  0  0  1  0  1  0  1  5  0  0  0  0  0  0  0  0  0\n",
      "   0  0]\n",
      " [ 0  0  0  0  0  0  0  0  3  0  1  0  0  0  0  5  0  1  0  0  0  0  0  0\n",
      "   0  0]\n",
      " [ 0  0  2  0  0  0  0  0  0  0  0  0  1  1  6  0  0  0  0  0  0  0  0  0\n",
      "   0  0]\n",
      " [ 1  0  0  0  0  0  0  0  1  0  2  0  0  0  0  0  0  6  0  0  0  0  0  0\n",
      "   0  0]\n",
      " [ 0  0  3  0  0  0  4  0  0  2  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0]\n",
      " [ 0  0  0  0  0  0  0  0  5  0  0  0  0  0  0  0  0  3  0  0  0  0  0  0\n",
      "   0  0]\n",
      " [ 0  0  0  0  0  0  1  0  0  0  0  2  0  2  3  0  0  0  0  0  0  0  0  0\n",
      "   0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  1  0  1  5  0  0  0  0  0  0  0  1  0  0\n",
      "   0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  4  0  0  1  0  0  0  0  0  0  0  0  4  0\n",
      "   0  0]\n",
      " [ 1  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  6  0  0  0  0  0  0\n",
      "   0  0]\n",
      " [ 0  0  0  0  0  0  0  0  3  0  0  0  0  3  0  0  0  2  0  0  0  0  0  0\n",
      "   0  0]\n",
      " [ 1  0  2  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  5]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.42      0.50      0.45        10\n",
      "           1       0.00      0.00      0.00         9\n",
      "           2       0.31      1.00      0.48        10\n",
      "           3       0.00      0.00      0.00         8\n",
      "           4       0.00      0.00      0.00         8\n",
      "           5       0.00      0.00      0.00         8\n",
      "           6       0.64      0.90      0.75        10\n",
      "           7       1.00      0.56      0.71         9\n",
      "           8       0.37      1.00      0.54        10\n",
      "           9       0.58      0.70      0.64        10\n",
      "          10       0.42      1.00      0.59        10\n",
      "          11       0.50      0.60      0.55        10\n",
      "          12       0.54      0.70      0.61        10\n",
      "          13       0.21      0.50      0.29        10\n",
      "          14       0.29      0.50      0.37        10\n",
      "          15       0.56      0.50      0.53        10\n",
      "          16       0.00      0.00      0.00        10\n",
      "          17       0.21      0.60      0.32        10\n",
      "          18       0.00      0.00      0.00         9\n",
      "          19       0.00      0.00      0.00         8\n",
      "          20       0.00      0.00      0.00         8\n",
      "          21       1.00      0.12      0.22         8\n",
      "          22       1.00      0.44      0.62         9\n",
      "          23       0.00      0.00      0.00         8\n",
      "          24       0.00      0.00      0.00         8\n",
      "          25       1.00      0.56      0.71         9\n",
      "\n",
      "    accuracy                           0.42       239\n",
      "   macro avg       0.35      0.39      0.32       239\n",
      "weighted avg       0.36      0.42      0.34       239\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import csv\n",
    "\n",
    "print(Y_validate1_pred)\n",
    "cm = confusion_matrix(Y_validate_1, Y_validate1_pred)\n",
    "print(cm)\n",
    "cr = classification_report(Y_validate_1, Y_validate1_pred)\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test - Predict Using Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test1_pred = classifier.predict(X_test1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test - Output - Confusion Matrix and Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2 13 17  2  0 17 11 17 22 13  6  9 11  8  2 10  0  8  2 12 16  0  2 17\n",
      "  8  1 22  8 17  6 14 17 10 14 10 10  2  8  8 12 12 10 13 10 10 17 10 14\n",
      " 17  0  7  8 10 10 14  2  0  9 17 14 12  6 11 14 17  6  6 14 12 13 13 14\n",
      " 13  8 12  6 10 17  6  8]\n",
      "[[2 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0]\n",
      " [0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 2 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 1 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 2 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 1 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 1 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 1 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0]\n",
      " [1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 1 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 2 0 0 0 0 0 0 0 0]\n",
      " [1 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.50      0.44         4\n",
      "           1       1.00      0.50      0.67         2\n",
      "           2       0.29      0.50      0.36         4\n",
      "           3       0.00      0.00      0.00         3\n",
      "           4       0.00      0.00      0.00         2\n",
      "           5       0.00      0.00      0.00         2\n",
      "           6       0.43      0.75      0.55         4\n",
      "           7       1.00      0.33      0.50         3\n",
      "           8       0.33      1.00      0.50         3\n",
      "           9       1.00      0.50      0.67         4\n",
      "          10       0.18      0.67      0.29         3\n",
      "          11       1.00      0.75      0.86         4\n",
      "          12       0.17      0.33      0.22         3\n",
      "          13       0.50      0.75      0.60         4\n",
      "          14       0.25      0.67      0.36         3\n",
      "          15       0.00      0.00      0.00         3\n",
      "          16       1.00      0.33      0.50         3\n",
      "          17       0.27      0.75      0.40         4\n",
      "          18       0.00      0.00      0.00         3\n",
      "          19       0.00      0.00      0.00         2\n",
      "          20       0.00      0.00      0.00         3\n",
      "          21       0.00      0.00      0.00         3\n",
      "          22       0.50      0.33      0.40         3\n",
      "          23       0.00      0.00      0.00         2\n",
      "          24       0.00      0.00      0.00         3\n",
      "          25       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.38        80\n",
      "   macro avg       0.32      0.33      0.28        80\n",
      "weighted avg       0.35      0.38      0.31        80\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(Y_test1_pred)\n",
    "cm = confusion_matrix(Y_test1, Y_test1_pred)\n",
    "print(cm)\n",
    "cr = classification_report(Y_test1, Y_test1_pred)\n",
    "print(cr)\n",
    "\n",
    "pd.DataFrame(Y_test1_pred).to_csv('output/Base-MLP-DS1.csv', header = None)\n",
    "with open('output/Base-MLP-DS1.csv', 'a') as fd:\n",
    "    fd.write('\\n\\nConfusion Matrix\\n\\n')\n",
    "    fd.write(pd.DataFrame(cm).to_csv())\n",
    "    fd.write('\\n\\n Classification Report\\n\\n')\n",
    "    fd.write(cr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base-MLP-DS2\n",
    "a baseline Multi-Layered Perceptron with 1 hidden layer of100 neurons, sigmoid/logistic as activation function, stochastic gradient descent, and default values for the rest of the parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing and Splitting the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train2 = pd.read_csv(\"dataset/train_2.csv\", header=None)\n",
    "dataset_validate2 = pd.read_csv(\"dataset/val_2.csv\",header=None)\n",
    "dataset_test2_no_label_2 = pd.read_csv(\"dataset/test_no_label_2.csv\",header=None)\n",
    "dataset_test2_with_label_2 = pd.read_csv(\"dataset/test_with_label_2.csv\",header=None)\n",
    "X_training_2 = dataset_train2.iloc[:, :-1].values\n",
    "Y_training_2 = dataset_train2.iloc[:, -1].values\n",
    "X_validate_2 = dataset_validate2.iloc[:, :-1].values\n",
    "Y_validate_2 = dataset_validate2.iloc[:, -1].values\n",
    "X_test2 = dataset_test2_no_label_2.iloc[:, ].values\n",
    "Y_test2 = dataset_test2_with_label_2.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Using Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='logistic', hidden_layer_sizes=100, solver='sgd')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = MLPClassifier(hidden_layer_sizes=(100), activation='logistic', solver='sgd')\n",
    "classifier.fit(X_training_2,Y_training_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate - Predict Using Validate Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_validate2_pred = classifier.predict(X_validate_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate - Output - Confusion Matrix and Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9 7 1 ... 8 0 1]\n",
      "[[144   3   1   0   6   0   0   0   8   3]\n",
      " [  4 367   0   0   1   1   0   0   1   1]\n",
      " [  1   2  15   0   2   1   0   0  18   6]\n",
      " [  1   8   0  30   2   3   0   1   0   0]\n",
      " [ 10   0   0   0 104   5   0   0   4  27]\n",
      " [  0   6   0   1   4 145   1   1   0   7]\n",
      " [  1   6   0   0   3   0  30   0   1   4]\n",
      " [  1   3   0   0   0   2   0  38   0   1]\n",
      " [  4  10   1   0   5   0   1   0 124   5]\n",
      " [  2   3   1   0  13  12   1   0   2 341]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.87      0.86       165\n",
      "           1       0.90      0.98      0.94       375\n",
      "           2       0.83      0.33      0.48        45\n",
      "           3       0.97      0.67      0.79        45\n",
      "           4       0.74      0.69      0.72       150\n",
      "           5       0.86      0.88      0.87       165\n",
      "           6       0.91      0.67      0.77        45\n",
      "           7       0.95      0.84      0.89        45\n",
      "           8       0.78      0.83      0.81       150\n",
      "           9       0.86      0.91      0.89       375\n",
      "\n",
      "    accuracy                           0.86      1560\n",
      "   macro avg       0.87      0.77      0.80      1560\n",
      "weighted avg       0.86      0.86      0.85      1560\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(Y_validate2_pred)\n",
    "cm2 = confusion_matrix(Y_validate_2, Y_validate2_pred)\n",
    "print(cm2)\n",
    "cr2 = classification_report(Y_validate_2, Y_validate2_pred)\n",
    "print(cr2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test - Predict Using Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test2_pred = classifier.predict(X_test2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test - Output - Confusion Matrix and Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9 0 4 5 9 1 1 3 8 9 0 1 3 9 9 3 9 9 7 1 6 1 9 7 9 8 1 1 8 8 9 8 8 9 8 1 5\n",
      " 9 1 1 1 7 9 5 9 9 1 1 5 1 9 4 5 9 0 0 8 5 9 1 1 9 0 0 9 0 1 4 0 0 3 0 1 9\n",
      " 5 8 9 1 0 4 7 1 0 5 0 9 9 9 7 1 8 4 1 1 5 1 9 9 0 0 4 8 8 2 4 5 8 5 5 4 1\n",
      " 9 5 5 8 9 8 0 8 9 1 5 5 9 1 1 2 4 4 9 1 1 8 1 9 1 4 9 0 8 5 0 1 4 4 4 9 9\n",
      " 5 1 1 5 9 1 5 0 1 5 5 3 0 8 0 1 1 1 1 1 9 0 5 9 5 0 4 1 1 0 0 5 4 1 9 9 4\n",
      " 1 9 9 0 3 1 9 1 9 5 7 9 7 9 9 5 0 9 0 5 5 8 1 5 1 4 5 1 0 9 0 8 1 1 9 8 1\n",
      " 9 4 9 3 9 5 8 1 9 1 4 9 1 6 5 9 8 1 2 0 9 9 1 1 5 0 9 7 9 1 1 1 9 0 9 5 1\n",
      " 1 9 1 1 1 5 5 9 2 7 8 5 4 9 1 7 8 5 8 9 5 0 4 4 6 0 9 0 1 9 1 3 9 8 8 1 9\n",
      " 1 0 8 5 1 5 9 5 1 1 1 7 1 3 9 9 1 9 1 8 5 9 9 7 9 1 9 9 2 5 9 0 1 9 5 1 9\n",
      " 4 1 6 7 1 9 4 8 9 5 8 0 5 5 4 9 9 5 3 8 8 1 9 4 1 1 1 0 9 0 9 9 8 8 1 1 1\n",
      " 9 5 1 5 1 4 1 9 8 8 1 9 1 1 1 9 4 4 9 8 9 9 0 1 5 1 2 8 2 1 1 9 0 9 8 7 8\n",
      " 9 8 0 5 6 1 9 1 1 9 1 4 5 9 9 0 9 8 0 9 5 4 8 9 0 1 9 9 1 1 9 9 5 1 0 0 1\n",
      " 0 9 8 8 9 9 9 9 1 9 8 0 1 0 1 9 1 8 8 9 9 4 1 8 7 8 9 8 8 9 5 9 5 0 8 4 1\n",
      " 1 1 0 9 4 9 8 9 0 1 5 4 1 8 1 3 0 0 1 9 0 5 4 9 0 8 1 5 8 9 1 1 9 4 0 1 9\n",
      " 6 5]\n",
      "[[ 46   3   1   0   0   1   0   0   1   3]\n",
      " [  3 119   0   1   0   1   0   0   1   0]\n",
      " [  0   0   5   0   0   1   0   0   8   1]\n",
      " [  2   1   0  10   0   2   0   0   0   0]\n",
      " [  5   1   0   0  28   2   0   0   3  11]\n",
      " [  0   0   0   0   1  50   0   0   0   4]\n",
      " [  1   3   1   0   1   0   6   0   2   1]\n",
      " [  0   0   0   0   0   0   0  15   0   0]\n",
      " [  1   1   0   0   0   0   0   0  44   4]\n",
      " [  2   0   0   0   8   6   0   0   1 108]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.84      0.80        55\n",
      "           1       0.93      0.95      0.94       125\n",
      "           2       0.71      0.33      0.45        15\n",
      "           3       0.91      0.67      0.77        15\n",
      "           4       0.74      0.56      0.64        50\n",
      "           5       0.79      0.91      0.85        55\n",
      "           6       1.00      0.40      0.57        15\n",
      "           7       1.00      1.00      1.00        15\n",
      "           8       0.73      0.88      0.80        50\n",
      "           9       0.82      0.86      0.84       125\n",
      "\n",
      "    accuracy                           0.83       520\n",
      "   macro avg       0.84      0.74      0.77       520\n",
      "weighted avg       0.83      0.83      0.82       520\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(Y_test2_pred)\n",
    "cm2 = confusion_matrix(Y_test2, Y_test2_pred)\n",
    "print(cm2)\n",
    "cr2 = classification_report(Y_test2, Y_test2_pred)\n",
    "print(cr2)\n",
    "\n",
    "pd.DataFrame(Y_test2_pred).to_csv('output/Base-MLP-DS2.csv', header = None)\n",
    "with open('output/Base-MLP-DS2.csv', 'a') as fd:\n",
    "    fd.write('\\n\\nConfusion Matrix\\n\\n')\n",
    "    fd.write(pd.DataFrame(cm2).to_csv())\n",
    "    fd.write('\\n\\n Classification Report\\n\\n')\n",
    "    fd.write(cr2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
